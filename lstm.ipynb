{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle-lstm",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb7x0OGVvkqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c7ab4195-d195-4bac-b309-6ef9237fe167"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "folder_path = '/content/gdrive/My Drive/Colab Notebooks/Data 144 Kaggle Challenge/'\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yS3NJi0v9jC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(folder_path+'yelp_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rimNRJfMwUaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = train\n",
        "df = df.reset_index(drop=True)\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "#    text = re.sub(r'\\W+', '', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hmi2fe6xa5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned'] = df['text'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAjLBsOqxkIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a731bec-2b87-4fd6-ddd2-cf2aea36c8d1"
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 50000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df['cleaned'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 287264 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vkOZ-fl0JNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "adae2a14-11e8-42be-ec86-da48d28c7e47"
      },
      "source": [
        "X = tokenizer.texts_to_sequences(df['cleaned'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (240000, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jLdqyPM0M_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37b66632-63ed-4b67-ea83-431a0aabfb5e"
      },
      "source": [
        "Y = pd.get_dummies(df['is_good_rating']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (240000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRElA6hX0O8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9eed737-caee-49a9-b948-479f2fd443d2"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(192000, 250) (192000, 2)\n",
            "(48000, 250) (48000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBz1m7uX0T88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "d50a53fd-8bf8-4460-da84-449b88bb5c82"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(200, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 250, 100)          5000000   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 250, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 400)               481600    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 802       \n",
            "=================================================================\n",
            "Total params: 5,482,402\n",
            "Trainable params: 5,482,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2614a43f-c399-437b-e075-56b06cd07aa5",
        "id": "A9iRNRDp7MiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 128\n",
        "model.fit(X, Y, epochs=1, batch_size=batch_size,validation_split=0.5)\n",
        "drive.mount('/content/gdrive')\n",
        "folder_path = '/content/gdrive/My Drive/Colab Notebooks/Data 144 Kaggle Challenge/'\n",
        "test = pd.read_csv(folder_path+'yelp_test.csv')\n",
        "test = test.reset_index(drop=True)\n",
        "test['cleaned'] = test['text'].apply(clean_text)\n",
        "X_test = tokenizer.texts_to_sequences(test['cleaned'].values)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_test.shape)\n",
        "preds = model.predict(X_test)\n",
        "print(preds.shape)\n",
        "predictions = preds.argmax(axis=1)\n",
        "print(predictions[:5])\n",
        "sample = pd.read_csv(folder_path+'yelp_sample.csv')\n",
        "sample.is_good_rating = predictions\n",
        "sample.set_index('review_id', inplace=True)\n",
        "sample.to_csv('preds_bilstm1.csv')\n",
        "!cp preds_bilstm1.csv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data\\ 144\\ Kaggle\\ Challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 120000 samples, validate on 120000 samples\n",
            "Epoch 1/1\n",
            "  9856/120000 [=>............................] - ETA: 1:07:04 - loss: 0.2186 - acc: 0.9136"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvmYuPxc-Pe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, Y, epochs=1, batch_size=batch_size*2,validation_split=0.5)\n",
        "drive.mount('/content/gdrive')\n",
        "folder_path = '/content/gdrive/My Drive/Colab Notebooks/Data 144 Kaggle Challenge/'\n",
        "test = pd.read_csv(folder_path+'yelp_test.csv')\n",
        "test = test.reset_index(drop=True)\n",
        "test['cleaned'] = test['text'].apply(clean_text)\n",
        "X_test = tokenizer.texts_to_sequences(test['cleaned'].values)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_test.shape)\n",
        "preds = model.predict(X_test)\n",
        "print(preds.shape)\n",
        "predictions = preds.argmax(axis=1)\n",
        "sample = pd.read_csv(folder_path+'yelp_sample.csv')\n",
        "sample.is_good_rating = predictions\n",
        "sample.set_index('review_id', inplace=True)\n",
        "sample.to_csv('preds_bilstm2.csv')\n",
        "!cp preds_bilstm2.csv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Data\\ 144\\ Kaggle\\ Challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIawgBr_EuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}